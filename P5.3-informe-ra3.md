# Informe de resultados RA3
## a.) Componentes y funcionamiento de los servicios del servidor
Los componentes y servicios que intervienen en el despliegue de P5.2 son los siguientes:
- Contenedor Docker: Es el entorno aislado donde se ejecuta WildFly y la aplicación REST. Proporciona una forma de empaquetar y desplegar la aplicación de manera consistente en diferentes entornos.
- WildFly: Es el servidor de aplicaciones Java EE que se encarga de gestionar la ejecución de la aplicación REST. Proporciona servicios como la gestión de recursos, seguridad, y el contenedor web para servir las peticiones HTTP.
- Aplicación WAR: Es el archivo empaquetado que contiene la aplicación REST. Incluye el código fuente, las dependencias y los archivos de configuración necesarios para que la aplicación funcione correctamente en WildFly.
- Puertos 8080/9990: El puerto 8080 es el puerto estándar para servir aplicaciones web, y es donde WildFly escucha las peticiones HTTP. El puerto 9990 es el puerto de administración de WildFly, utilizado para acceder a la consola de administración y realizar tareas de configuración y monitoreo.
- Endpoint REST: Es la URL específica dentro de la aplicación REST que maneja las peticiones HTTP. Por ejemplo, si la aplicación se despliega con un contexto base de "/crud-file", el endpoint podría ser "http://localhost:8080/crud-file".

Para verificar si el contenedor está activo además de verificar los puertos usa el siguiente comando: `docker ps`
![img_1.png](assets/img/img_1.png)
Para verificar los logs del contenedor y el acceso a la aplicación se puede usar el comando: `docker logs -f wildfly`
![img_2.png](assets/img/img_2.png)
Para verificar la respuesta del endpoint se puede usar el comando: `curl http://localhost:8080/crud-file`
![img_3.png](assets/img/img_3.png)

## b.) Archivos principales de configuración y bibliotecas compartidas
Los archivos de configuración principales de WildFly se encuentran en la ruta `/opt/jboss/wildfly/standalone/configuration`. En esta ubicación, se pueden encontrar archivos como `standalone.xml`, que es el archivo de configuración principal del servidor. En este archivo, se pueden ajustar diversos parámetros relacionados con la configuración del servidor, como la gestión de recursos, la seguridad, los subsistemas, y las conexiones a bases de datos, entre otros.
![img_4.png](assets/img/img_4.png)

Además, en el archivo `build.gradle.kts` se pueden identificar las dependencias que se consideran "provided", lo que significa que el servidor de aplicaciones ya incluye estas bibliotecas y no es necesario empaquetarlas dentro del WAR. Esto tiene la ventaja de reducir el tamaño del archivo WAR y evitar conflictos de versiones, ya que el servidor se encarga de proporcionar las bibliotecas necesarias en tiempo de ejecución.

!https://github.com/ricitos2001/2526_DAW_u5.3_jakarta-wildfly-gradle-otra/blob/ab23742fc3b5f0f951887e295d474ceac791f83d/build.gradle#L20-L22

## c.) Cooperación con el servidor web (proxy / reverse proxy) y https
En un entorno real, se podría configurar Nginx como un reverse proxy para WildFly para publicar la API bajo una ruta clara, como por ejemplo `/api/`. Esto permitiría que las peticiones a `http://example.com/api/` sean redirigidas internamente a `http://wildfly:8080/`, donde WildFly está ejecutando la aplicación REST. Además, se evitaría exponer el puerto 9990 hacia el exterior, ya que solo se necesitaría exponer el puerto 80 para HTTP y el puerto 443 para HTTPS en Nginx.

La configuración de Nginx para redirigir a WildFly y habilitar HTTPS sería la siguiente:
```Nginx
server {
    listen 80;
    server_name example.com;
    return 301 https://$host$request_uri;
}

server {
    listen 443 ssl;
    server_name example.com;

    ssl_certificate /etc/letsencrypt/live/example.com/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/example.com/privkey.pem;

    location /api/ {
        proxy_pass http://wildfly:8080/;
        proxy_set_header Host $host;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }

    # bloquear acceso a /management o 9990 aquí si fuera expuesto
}
```

## d.) Mecanismos de seguridad del servidor de aplicaciones
En mi despliegue de P5.2, apliqué las siguientes medidas de seguridad:
1. No expuse el puerto de administración (9990) al exterior, lo que impide que usuarios no autorizados puedan acceder a la consola de administración de WildFly desde fuera del contenedor.
2. Utilicé credenciales seguras para la cuenta de administración de WildFly, asegurándome de que la contraseña sea fuerte y no se utilicen valores predeterminados.
3. Configuré la gestión de secretos utilizando variables de entorno para almacenar las credenciales de administración, evitando incluir información sensible directamente en el código fuente o en archivos de configuración.
4. Configuré el registro y trazabilidad de WildFly para asegurar que todas las actividades relevantes sean registradas en los logs, lo que facilita la detección de posibles intentos de acceso no autorizados o actividades sospechosas.

[NOTA]: En las siguientes caputras de pantalla se muestra la configuración de puertos expuestos en el contenedor Docker, confirmando que solo el puerto 8080 está expuesto al exterior, mientras que el puerto 9990 no lo está, lo que refuerza la seguridad al limitar el acceso a la consola de administración de WildFly, además de un intento de acceso a la consola de administración desde el exterior que resulta en un error de conexión, confirmando que el puerto 9990 no está accesible desde fuera del contenedor.
![img_11.png](assets/img/img_11.png)
![img_10.png](assets/img/img_10.png)
![img_9.png](assets/img/img_9.png)
Para agregar una clave de administración de WildFly utilizando Docker Secrets, se puede utilizar el siguiente comando para crear un secreto con la contraseña de administración:
```bash
echo "mi_password_admin" | docker secret create wildfly_admin_password -
```

## e.) Componentes web del servidor de aplicaciones
Mi aplicación REST se empaqueta como un archivo WAR (Web Application Archive), que es un formato estándar para distribuir aplicaciones web en Java. El WAR contiene el código fuente de la aplicación, las dependencias necesarias, y los archivos de configuración. Al desplegar el WAR en WildFly, el servidor lo descomprime y lo configura para que esté disponible bajo un contexto específico. El contexto o ruta base de la aplicación es la parte de la URL que sigue al puerto y que identifica la aplicación dentro del servidor. Por ejemplo, si el contexto es "/crud-file", entonces la URL para acceder a la aplicación sería `http://localhost:8080/crud-file`. El contenedor web de WildFly se encarga de recibir las peticiones HTTP, enrutar las solicitudes al controlador adecuado dentro de la aplicación REST, y enviar las respuestas de vuelta al cliente.
![img_7.png](assets/img/img_7.png)

La siguiente imagen muestra el log del servidor WildFly confirmando que la aplicación REST está siendo servida correctamente y que las peticiones a la URL `http://localhost:8080/crud-file/api/tasks` están siendo procesadas sin problemas, lo que indica que el despliegue ha sido exitoso y la aplicación está funcionando como se esperaba.
![img_8.png](assets/img/img_8.png)

## f.) Parámetros necesarios para el despliegue
En mi despliegue de P5.2, los parámetros necesarios fueron los siguientes:
1. Nombre del contenedor: Asigné el nombre "wildfly" al contenedor Docker para facilitar su identificación y gestión. Si el nombre estuviera mal, podría resultar difícil identificar el contenedor correcto al ejecutar comandos de Docker, especialmente si hay múltiples contenedores en ejecución.
2. Puertos expuestos: Exposé el puerto 8080 para servir la aplicación REST y el puerto 9990 para la administración de WildFly. Si los puertos estuvieran mal configurados, la aplicación no estaría accesible desde el exterior, y no podría acceder a la consola de administración para realizar tareas de configuración o monitoreo.
3. Ruta de despliegue del WAR: Aseguré que el archivo WAR se desplegara en la ruta correcta dentro de WildFly, lo que permite que la aplicación esté disponible bajo el contexto esperado. Si la ruta de despliegue estuviera mal configurada, la aplicación no estaría accesible a través de la URL prevista, lo que podría causar confusión y dificultar la interacción con la aplicación.
4. Variables de entorno para credenciales: Utilicé variables de entorno para almacenar las credenciales de administración de WildFly, lo que mejora la seguridad al evitar incluir información sensible en el código fuente. Si las variables de entorno estuvieran mal configuradas, podría resultar en la imposibilidad de acceder a la consola de administración o en la exposición de credenciales sensibles, lo que representaría un riesgo de seguridad.
5. Comando de inicio de WildFly: Utilicé el comando `standalone.sh -b 0.0.

El comando utilizado para iniciar el contenedor Docker con WildFly fue el siguiente:
```bash
docker run -d --name wildfly -p 8080:8080 -p 9990:9990 quay.io/wildfly/wildfly:latest /opt/jboss/wildfly/bin/standalone.sh -b 0.0.0.0 -bmanagement 0.0.0.0
```
En caso de que uno de los parámetros este mal escrito o configurado, el contenedor podría no iniciar correctamente, la aplicación no estaría accesible, o podría haber problemas de seguridad. Por ejemplo, si el puerto 8080 no estuviera expuesto correctamente, no se podría acceder a la aplicación REST desde el exterior, lo que impediría su uso. Si el comando de inicio de WildFly estuviera mal configurado, el servidor podría no arrancar o no estar disponible en la dirección correcta, lo que también afectaría la accesibilidad de la aplicación.

## g.) Pruebas de funcionamiento y rendimiento
Realicé pruebas funcionales utilizando curl para verificar que los endpoints de mi aplicación REST estaba respondiendo correctamente. Por ejemplo, ejecuté el siguiente comando para probar el endpoint principal:

```bash
curl -X GET http://localhost:8080/crud-file/api/tasks -H "Content-Type: application/json" -d '{"id":"3"}'
curl -X POST http://localhost:8080/crud-file/api/tasks -H "Content-Type: application/json" -d '{"title":"Aprender curl","done":false}'
curl -X GET http://localhost:8080/crud-file/api/tasks/5
curl -X DELETE http://localhost:8080/crud-file/api/tasks/5
curl -X PUT http://localhost:8080/crud-file/api/tasks/4 -H "Content-Type: application/json" -d '{"title":"Tarea actualizada","done":true}'
```

[NOTA]: En estos comandos, se están probando diferentes métodos HTTP (GET, POST, DELETE, PUT) para interactuar con los recursos de la aplicación REST. Cada comando incluye la URL del endpoint, el método HTTP, y en algunos casos, un cuerpo JSON con los datos necesarios para la operación; además, en las siguientes capturas se muestra el resultado final de cada comando, confirmando que la aplicación REST está funcionando correctamente y respondiendo a las peticiones como se esperaba.
![img_5.png](assets/img/img_5.png)
![img_6.png](assets/img/img_6.png)

Además, realize una prueba de rendimiento básica utilizando el comando ab (ApacheBench) para evaluar el rendimiento de mi aplicación REST desplegada en WildFly. A continuación, se detallan los comandos utilizados, los endpoints probados y un breve análisis de los resultados obtenidos:
```bash
ab -n 1000 -c 10 http://localhost:8080/crud-file
```

En este comando, se especifica que se realizarán 1000 peticiones (-n 1000) con una concurrencia de 10 peticiones simultáneas (-c 10) al endpoint http://localhost:8080/crud-file:
![img.png](assets/img/img.png)

## h.) Documentación de administración y recomendaciones
```
RECOMIENDO, hacer antes el punto i) y luego redactar esta sección con lo aprendido.

Redacta una mini-guía de administración para tu despliegue de P5.2 que incluya:

Cómo levantar WildFly.
Cómo desplegar una nueva versión del WAR.
Cómo comprobar el estado (logs y endpoint de prueba).
Recomendaciones para evitar errores comunes.
Debe ser reproducible para otra persona del equipo.

Evidencias típicas

Manual con instrucciones claras y paso a paso, acompañado de: - Ficheros Docker: dockerfile y compose. - Arquitectura de desplieuge - Comandos clave (docker, despliegue, pruebas). - URLs de prueba. - Acceso a logs y endpoints. - Pruebas de funcionamiento. - Pruebas de rendimiento. - Recomendaciones de seguridad.
```

## i.) Virtualización, nube o contenedores en el despliegue

```
Realiza un despliegue haciendo uso de docker compose que auné todo. Servidor web (Nginx) + servidor de aplicaciones (WildFly) + tu aplicación REST.

Ten en cuenta volúmenes para logs, secretos, healthchecks y reinicio automático, limitación de recursos, redes, etc.

Una mejora adicional, sería separar frontend y backend en contenedores distintos, con comunicación entre ellos, y no exponer el backend directamente al host.
```